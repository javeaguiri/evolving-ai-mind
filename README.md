

üß† evolving-mind-ai
Self-Evolving, Low-Cost Cognitive Automation System
evolving-mind-ai is an intelligent low-cost automation brain that creates, manages, and evolves its own process flows and data schemas. It harnesses LLM-powered reasoning to generate new workflows and database structures dynamically, while routine tasks run entirely through low-cost AWS Lambda + PostgreSQL operations.

‚öôÔ∏è Design Principles
Principle	Description
Intelligent & Adaptive	Uses LLM only to create new task/process flows and SQL schemas when novelty is detected.
Low-Cost Operation	Everyday tasks run through AWS Lambda serverless functions + PostgreSQL free tier.
Autonomous Schema Evolution	The system evolves PGC (config schemas) and PGD (domain data tables) automatically.
Composability	Modular services‚ÄîPROC, SERV, API‚Äîare stateless and functionally replaceable.
GitHub Readability	Fully visualized architecture, directory outline, and YAML/operator clarity.
Target Cost: ~$0.03‚Äì$0.05 per month
Stack: Slack ‚Üí AWS Lambda ‚Üí PostgreSQL ‚Üí LLM (OpenAI / Anthropic-compatible layer)

üèóÔ∏è System Architecture
text
graph TD;
  Slack[Slack Bot UI] --> PROC[Rules Engine (PROC)];
  PROC --> SERV[Service Layer (AWS Lambda)];
  SERV --> API[API Gateway + PostgreSQL Service Endpoints];
  API --> PGC[(PostgreSQL Schema Config - PGC)];
  API --> PGD[(PostgreSQL Domain Tables - PGD)];
  PROC --> LLM[LLM Layer (Flow & Schema Synthesizer)];

  LLM --> PROC;
Flow Summary
Slack input triggers low-cost Lambda endpoint.

Rules Engine routes intents using pre-defined function routes or schema-driven logic.

Service layer executes SQL operations through PostgreSQL adapters (new Function()‚Äìbased runners).

LLM layer steps in only when new workflows or entity types are needed.

üß∞ Core Components
1. Slack Bot (UI Layer)
Natural interface for creating & executing flows.

Example Slash Commands

text
/create-domain project-management
/create-task-flow "weekly goal planning"
/list-domains
/run-flow project-management:weekly-goal-planning
Each interaction maps to a PROC orchestration, which runs in Lambda and calls into the PostgreSQL-backed service layer.

2. Rules Engine (PROC Layer)
Routes messages, creates temporary execution plans, and reuses prebuilt task flows.

javascript
const ROUTES = {
  "create-domain": llmGenerateSchema(),          // LLM creates new PGC entry + tables
  "create-task-flow": llmGenerateTaskFlow(),     // LLM defines procedural SQL flow
  "run-flow": executeProcessFlow(),              // Executes defined task logic
  "list-domains": pgcListDomains()               // Reads PGC and formats via prettyPrint()
};
Workflows execute via new Function() to enable dynamic orchestration.

All persistent state (schemas, flows, logs) lives in PostgreSQL.

AWS SQS supports async handoffs and decoupled event orchestration.

3. Service Layer (SERV)
Stateless Lambda endpoints that implement core CRUD and orchestration services.

Endpoint	Purpose
POST /api/schema	Create or update entries in PGC-Schema tables
POST /api/domain	Insert domain data into PGD tables
GET /api/process	Retrieve process definitions for execution
POST /api/process/run	Execute stored process flows
POST /api/pretty	Format and summarize process output (LLM optional)
GET /api/health	System health and status check
Example AWS Lambda Handler

javascript
export const handler = async (event) => {
  const { path, body } = event;
  if (path === "/api/process/run") {
    return runProcessFlow(body);
  }
  if (path === "/api/schema") {
    return updatePGCSchema(body);
  }
  return { statusCode: 404, body: "Not found" };
};
4. PostgreSQL Backbone
A unified data store for configuration + operational domains.

PGC (PostgreSQL Config Tables)

Table	Description
PGC_Schema	Defines entity configurations, relationships, indexes.
PGC_Process	Stores workflow metadata and SQL flow definitions.
PGD (PostgreSQL Domain Tables)

Table	Description
PGD_<Domain>	Dynamically created tables for user-specific domains.
PGD_Events	Logs runtime events and flow executions.
5. YAML Configuration (Declarative)
Declarative configs define schema evolution rules and CRUD metadata for code generation‚Äînot domain data.

text
# config/pgc-config.yaml
pgc:
  - name: SchemaDefinition
    fields:
      - { name: entity_name, type: text }
      - { name: field_definitions, type: jsonb }

  - name: ProcessDefinition
    fields:
      - { name: process_name, type: text }
      - { name: sql_script, type: text }
      - { name: version, type: integer }
üí° Example LLM Flow Generation
When a user sends /create-domain health-tracking, the LLM automatically:

Proposes a schema for PGD_health_tracking

Generates DDL (CREATE TABLE ‚Ä¶) persisted to PGC_Schema

Registers metadata in PGC_Process

Responds via Slack with a summary:

text
üß¨ Domain "health-tracking" created  
Tables: health_metrics, activities  
You can now run `/create-task-flow "daily summary"` to generate a workflow
üí∞ Cost Model
text
25 daily ops: PostgreSQL query calls via Lambda (0 tokens)
5 LLM ops/day: 22.5K tokens/week ‚Üí 55K/month ‚Üí ~$0.03
AWS Lambda (Free tier)
PostgreSQL (Free tier)
Slack API (Free tier)
üöÄ Phase Plan
Phase 1 ‚Äî AWS & PostgreSQL Foundation
Build Lambda + PostgreSQL integration

Deploy /api/schema and /api/process endpoints

Test new Function() orchestration model

Phase 2 ‚Äî Core Logic & CRUD Services
Finalize PGC/PGD table models

Implement Lambda endpoints and Slack routing

Add unit/integration testing

Phase 3 ‚Äî LLM Schema/Flow Generation
Enable Slash /create-domain + /create-task-flow

Automate SQL generation and persistence

Phase 4 ‚Äî Polish & Expansion
Add GitHub Actions pipeline

Pretty output formatting with LLM fallback

Visualization metrics dashboard

# üìÅ Directory Structure

```
evolving-mind-ai/
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ process/                          # PROC-*: Core business logic layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ interpret.js                  # PROC-Interpret: AI instruction interpretation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ run-workflow.js               # PROC-Workflow: Workflow orchestration  
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sync-brain.js                 # PROC-Sync: Brain state synchronization
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ping.js                       # PROC-Ping: Vercel‚ÜíLLM health check
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.js                      # PROC-Router: /api/process/ endpoints
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ service/                          # SERV-*: SPD/SPC database operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ table.js                      # SERV-Table: CRUD operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entity.js                     # SERV-Entity: Multi-table operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schema.js                     # SERV-Schema: DDL operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ query.js                      # SERV-Query: Complex SELECTs/JOINs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.js                      # SERV-Router: /api/service/ endpoints
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ slackbot/                         # SLACK-*: Vercel Slack bot (Bolt.js)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ping.js                       # SLACK-Ping: /ping [1-10] threaded test
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ second-brain.js               # SLACK-SecondBrain: Dynamic router/help
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ commands.js                   # SLACK-Commands: Dynamic registry
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.js                      # SLACK-Router: Bolt ExpressReceiver
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ shared/                           # SHARED-*: Cross-cutting concerns
‚îÇ       ‚îú‚îÄ‚îÄ graph-client.js               # SHARED-Graph: GraphQL client
‚îÇ       ‚îú‚îÄ‚îÄ auth.js                       # SHARED-Auth: JWT/API key validation
‚îÇ       ‚îú‚îÄ‚îÄ config.js                     # SHARED-Config: Env vars/flags
‚îÇ       ‚îî‚îÄ‚îÄ logger.js                     # SHARED-Logger: Structured JSON logs
‚îÇ
‚îú‚îÄ‚îÄ vercel.json                           # VERCEL-Routes: /slackbot/* routing
‚îú‚îÄ‚îÄ package.json                          # NPM-Deps: @slack/bolt + runtime deps
‚îî‚îÄ‚îÄ README.md                             # SETUP-Guide: Deployment instructions
```
üß™ Scaffolding Test Components (Ping Flows)
Purpose: Development diagnostics + production troubleshooting. These ping endpoints isolate integration points between layers (Slack, Lambda, SQS, LLM, PostgreSQL). Always available for manual testing via Slack commands and curl.

Diagnostic Matrix:

Test	Slack Cmd	curl Cmd	Validates
Slackbot	/ping-api	N/A	Slack ‚Üí Lambda wiring
LLM	/ping-llm	POST /proc/ping-llm	PROC + LLM
SQS Orchestration	/ping-sqs	N/A	PROC ‚Üí SQS ‚Üí SERV ‚Üí PROC ‚Üí Slack
PostgreSQL	N/A	GET /serv/ping-db	SERV + PostgreSQL
1. Slack ‚Üí Slackbot Lambda Only (/ping-api)
Validates: Slack slash command config + Slackbot Lambda (no PROC/SQS/LLM/DB).

Slack Command: /ping-api

Implementation: src/ui/slackbot/ping.js

javascript
export const handler = async (event) => {
  const { text = 'pong', channel_id, user_id } = JSON.parse(event.body || '{}');
  const correlationId = crypto.randomUUID();
  
  return {
    statusCode: 200,
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      response_type: 'in_channel',
      text: `ü§ñ **pong-api** from slackbot <@${user_id}><br/>correlationId: ${correlationId}`,
      thread_ts: event.body?.thread_ts
    })
  };
};
Expected Slack Response:

text
ü§ñ pong-api from slackbot @user
correlationId: abc123-def456
Troubleshooting: If this fails ‚Üí Slack app config or Slackbot Lambda issue.

2. HTTP ‚Üí PROC Ping (LLM Fortune Cookie) (POST /api/v1/proc/ping-llm)
Validates: PROC Lambda + LLM provider (no Slack/SQS/DB). Perfect for curl from terminal/CI.

curl Test:

bash
curl -X POST https://api.example.com/api/v1/proc/ping-llm \
  -H "Content-Type: application/json" \
  -H "X-Correlation-Id: test-123" \
  -d '{"test":"ping"}'
Implementation: src/proc/ping-llm.js (single handler for both curl + Slack)

javascript
import OpenAI from 'openai';

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

export const handler = async (event) => {
  const payload = parseUnifiedPayload(event);
  const correlationId = payload.correlationId || crypto.randomUUID();
  
  const completion = await openai.chat.completions.create({
    model: 'gpt-4o-mini',
    messages: [{ role: 'user', content: 'Fortune cookie about evolving-mind-ai + AWS Lambda' }]
  });
  
  const response = {
    success: true,
    message: completion.choices[0].message.content,
    model: completion.choices[0].message.model,
    correlationId
  };
  
  return formatResponse(payload.source, response);
};
Expected JSON Response:

json
{
  "success": true,
  "message": "Your AWS Lambda workflows will evolve smarter than you expect! üç™",
  "model": "gpt-4o-mini",
  "correlationId": "abc123"
}
Troubleshooting: If this fails ‚Üí LLM API key, PROC Lambda, or API Gateway issue.

3. Slack ‚Üí PROC Ping (LLM E2E) (/ping-llm)
Validates: Slack ‚Üí Slackbot ‚Üí PROC ‚Üí LLM ‚Üí Slack full pipeline.

Slack Command: /ping-llm

Slackbot Forwarding: src/ui/slackbot/commands.js

javascript
app.command('/ping-llm', async ({command, ack, respond}) => {
  await ack('‚è≥ Testing LLM integration‚Ä¶');
  
  const result = await invokeLambda('PROC-PingLLM', {
    source: 'slack',
    slackPayload: command,
    correlationId: crypto.randomUUID()
  });
  
  await respond({
    response_type: 'in_channel',
    text: `üîÆ **LLM pong-llm**<br/>${result.message}<br/>model: ${result.model}<br/>ID: ${result.correlationId}`
  });
});
Expected Slack Response:

text
üîÆ LLM pong-llm
"Your Lambda functions will achieve enlightenment! üç™"
model: gpt-4o-mini
ID: abc123
Troubleshooting: If /ping-api works but this fails ‚Üí PROC routing or LLM issue.

4. Slack ‚Üí PROC Ping with SQS (/ping-sqs)
Validates: Slack ‚Üí PROC ‚Üí SQS ‚Üí SERV ‚Üí PROC ‚Üí Slack orchestration pipeline.

Slack Command: /ping-sqs

Implementation Flow:

UI-SlackBot: ACK + forward to PROC-PingSQS

PROC-PingSQS: Queue test message to SYS-SQS-Workflow

SERV-PingSQS (SQS-triggered): Process ‚Üí queue completion

UI-SlackCallbackListener (SQS-triggered): Post result to Slack thread

Expected Slack Flow:

text
‚è≥ ping-sqs started‚Ä¶ (immediate ACK)

[30s later in same thread]
üì¨ ping-sqs complete!
‚úÖ 2 SQS hops, workflowId: abc123
Troubleshooting: If /ping-llm works but this fails ‚Üí SQS IAM, queue config, or orchestration issue.

Unified Payload Parser (Shared Across All Pings)
javascript
// src/shared/ping-utils.js
export function parseUnifiedPayload(event) {
  if (event.httpMethod) {  // API Gateway
    return {
      source: 'http',
      payload: JSON.parse(event.body || '{}'),
      correlationId: event.headers['X-Correlation-Id'] || crypto.randomUUID()
    };
  }
  if (event.slackPayload) {  // Slackbot forwarded
    return {
      source: 'slack',
      payload: event.slackPayload,
      correlationId: event.correlationId || crypto.randomUUID()
    };
  }
  throw new Error('Unknown event source');
}


‚úÖ Success Metrics
 <100K tokens/month

 95% operations handled via Lambda (no LLM)

 PostgreSQL schema evolution functional

 Slash commands /create-domain and /create-task-flow operational

 GitHub Actions build + status shield visible

Status: Phase 1 in progress ‚Äî building AWS-PostgreSQL-Lambda integration.
Repo Presentation: Designed for GitHub with full Markdown styling, Mermaid diagrams, and YAML clarity for developers.